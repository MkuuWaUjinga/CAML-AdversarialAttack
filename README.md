# CAML-AdversarialAttack
This repository is part of a seminar work on automatic differentiation and its importance for machine learning. 
The repository implemnts FGSM and i-FGSM attack methods on the MNIST dataset.

The code was adapted from [this pytorch tutorial](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html). Please dowload the trained model via [this link](https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h) and place it in your data folder. 

Here is an image ![Alt](./images/shift4->8_cropped.png?raw=true, "Successful i-FGSM Attack on MNIST")
